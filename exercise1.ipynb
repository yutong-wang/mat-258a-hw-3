{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minimizeBFGS (generic function with 3 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "# Minimizers #\n",
    "##############\n",
    "\n",
    "# Note: All minimizer functions returns an array L such that\n",
    "# L[1] = x^*, or the optimal point\n",
    "# L[2] = value of the objective function at the optimal point\n",
    "# L[3] = number of iterations used or DEFAULT_MAX_ITER\n",
    "\n",
    "const DEFAULT_MAX_ITER = 100\n",
    "const DEFAULT_TOLERANCE = 0.01\n",
    "\n",
    "# Minimization algorithm using gradient descent\n",
    "# f  the objective function\n",
    "# g  the gradient of f\n",
    "# x  an initial testing point\n",
    "# tolerance a small number\n",
    "function minimize(f,g, x::Vector, tolerance = DEFAULT_TOLERANCE, max_iter = DEFAULT_MAX_ITER)\n",
    "    alpha =0.3\n",
    "    beta = 0.7\n",
    "    iter = 0\n",
    "    tolerance = tolerance*norm(g(x))\n",
    "    while norm(g(x)) > tolerance && iter < max_iter\n",
    "        dx = -g(x)\n",
    "        t = 1\n",
    "        while f(x+t*dx) > f(x) + alpha*t*sum(g(x).*dx)\n",
    "            t = beta*t\n",
    "        end\n",
    "        x = x + t*dx\n",
    "        iter = iter + 1\n",
    "        print(\"$iter, \")\n",
    "    end\n",
    "    return [x, f(x), iter]\n",
    "end\n",
    "\n",
    "\n",
    "# Minimization algorithm using Newton's method\n",
    "# f  the objective function\n",
    "# g  the gradient of f\n",
    "# h  the Hessian of f\n",
    "# x  an initial testing point\n",
    "# tolerance a small number\n",
    "function minimizenewt(f,g, H, x::Vector, tolerance=DEFAULT_TOLERANCE, max_iter = DEFAULT_MAX_ITER)\n",
    "    alpha =0.3\n",
    "    beta = 0.7\n",
    "    iter = 0\n",
    "    \n",
    "    # Default mode is RELATIVE tolerance, comment out the line below for ABSOLUTE tolerance\n",
    "    tolerance = tolerance*norm(g(x))\n",
    "\n",
    "    while norm(g(x)) > tolerance && iter < max_iter\n",
    "        dx = -H(x)\\g(x)\n",
    "        t = 1\n",
    "        while f(x+t*dx) > f(x) + alpha*t*sum(g(x).*dx)\n",
    "            t = beta*t\n",
    "        end\n",
    "        x = x + t*dx\n",
    "        iter = iter + 1\n",
    "    end\n",
    "    if iter < max_iter\n",
    "        success =1\n",
    "    else\n",
    "        success =0\n",
    "    end\n",
    "    return [x, f(x), iter]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Minimization algorithm using Newton's method, with fix for nonpositive definite matrix\n",
    "# f  the objective function\n",
    "# g  the gradient of f\n",
    "# h  the Hessian of f\n",
    "# x  an initial testing point\n",
    "# tolerance a small number\n",
    "function minimizenewtnpd(f,g, H, x::Vector, tolerance=DEFAULT_TOLERANCE, max_iter = DEFAULT_MAX_ITER)\n",
    "    alpha =0.3\n",
    "    beta = 0.7\n",
    "    iter = 0\n",
    "    function fixnonposdefmat(A, epsilon=0.1)\n",
    "        M = eigfact(A)\n",
    "        V = M[:vectors]\n",
    "        L = M[:values]\n",
    "        X = [max(abs(vi), epsilon)::Float64 for vi in L]\n",
    "        L = diagm(X)\n",
    "        return (V'*L*V)\n",
    "    end\n",
    "    \n",
    "    # Default mode is RELATIVE tolerance, comment out the line below for ABSOLUTE tolerance\n",
    "    tolerance = tolerance*sqrt(sum(g(x).^2))\n",
    "\n",
    "    while sqrt(sum(g(x).^2)) > tolerance && iter < max_iter\n",
    "        if isposdef(H(x))\n",
    "            HH = H(x)\n",
    "        else\n",
    "            HH = fixnonposdefmat(H(x))\n",
    "        end\n",
    "        dx = -HH\\g(x)\n",
    "        t = 1\n",
    "        while f(x+t*dx) > f(x) + alpha*t*sum(g(x).*dx)\n",
    "            t = beta*t\n",
    "        end\n",
    "        x = x + t*dx\n",
    "        iter = iter + 1\n",
    "    end\n",
    "    return [x, f(x), iter]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Minimization algorithm using Newton's method, with fix for nonpositive definite matrix, version 2\n",
    "# f  the objective function\n",
    "# g  the gradient of f\n",
    "# h  the Hessian of f\n",
    "# x  an initial testing point\n",
    "# tolerance a small number\n",
    "function minimizenewtnpd2(f,g, H, x::Vector, tolerance=DEFAULT_TOLERANCE, max_iter = DEFAULT_MAX_ITER)\n",
    "    alpha =0.3\n",
    "    beta = 0.7\n",
    "    iter = 0\n",
    "    function fixnonposdefmat(A, epsilon=0.1)\n",
    "        M = eigfact(A)\n",
    "        V = M[:vectors]\n",
    "        L = M[:values]\n",
    "        X = [max(vi, epsilon)::Float64 for vi in L]\n",
    "        L = diagm(X)\n",
    "        return (V'*L*V)\n",
    "    end\n",
    "    \n",
    "    # Default mode is RELATIVE tolerance, comment out the line below for ABSOLUTE tolerance\n",
    "    tolerance = tolerance*norm(g(x))\n",
    "\n",
    "    while norm(g(x)) > tolerance && iter < max_iter\n",
    "        if isposdef(H(x))\n",
    "            HH = H(x)\n",
    "        else\n",
    "            HH = fixnonposdefmat(H(x))\n",
    "        end\n",
    "        dx = -HH\\g(x)\n",
    "        t = 1\n",
    "        while f(x+t*dx) > f(x) + alpha*t*sum(g(x).*dx)\n",
    "            t = beta*t\n",
    "        end\n",
    "        x = x + t*dx\n",
    "        iter = iter + 1\n",
    "    end\n",
    "    return [x, f(x), iter]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Minimization algorithm using BFGS\n",
    "# f  the objective function\n",
    "# g  the gradient of f\n",
    "# H  the initial guess of the INVERSE HESSIAN, you should set it to the identify matrix if you don't know\n",
    "# x  an initial testing point\n",
    "# tolerance a small number\n",
    "function minimizeBFGS(f,g, H, x::Vector, tolerance=DEFAULT_TOLERANCE, max_iter = DEFAULT_MAX_ITER)\n",
    "    alpha =0.3\n",
    "    beta = 0.7\n",
    "    iter = 0\n",
    "    \n",
    "    I = eye(length(x))\n",
    "    \n",
    "    # Default mode is RELATIVE tolerance, comment out the line below for ABSOLUTE tolerance\n",
    "    tolerance = tolerance*sqrt(sum(g(x).^2))\n",
    "\n",
    "    while norm(g(x)) > tolerance && iter < max_iter\n",
    "        dx = -H*g(x)\n",
    "        t = 1\n",
    "        while f(x+t*dx) > f(x) + alpha*t*sum(g(x).*dx)\n",
    "            t = beta*t\n",
    "        end\n",
    "        x1 = x + t*dx\n",
    "        s = t*dx\n",
    "        y = g(x1) - g(x)\n",
    "        rho = 1/dot(s,y)\n",
    "        H = (I- rho* s *(y'))*H*(I-rho*y*(s')) + rho*s*(s')\n",
    "        x = x1\n",
    "        iter = iter + 1\n",
    "    end\n",
    "    return [x, f(x), iter]\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legends:\n",
      "NM = Newton's method\n",
      "NMPDF1 = Newton's method with non-positive definite Hessian fix, WITH absolute value\n",
      "NMPDF2 = Newton's method with non-positive definite Hessian fix, WITHOUT absolute value\n",
      "BFGS = quasi-Newton method using BFGS approximation of inverse Hessian\n",
      "Correct = the correct outputs a minimizer function should spit out\n",
      "---------------------------------------------------------------------------------------\n",
      "Method     Coordinate of optimal point                  Value of minimum      # of iterations\n",
      "NM           3.000000             1.000000             0.000000                    1\n",
      "NMPDF1       3.000000             1.000000             0.000000                    1\n",
      "NMPDF2       3.000000             1.000000             0.000000                    1\n",
      "BFGS         3.000009             0.999972             0.000000                    4\n",
      "Correct      3.000000             1.000000             0.000000                    0\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# Simple test with a quadratic #\n",
    "################################\n",
    "\n",
    "m = 100\n",
    "n = 2\n",
    "x0 = [3;1]\n",
    "A = randn(m,n)\n",
    "b = A*x0\n",
    "f0(x) = 0.5*norm(A*x-b)^2\n",
    "g0(x) = A'*(A*x-b)\n",
    "H0(x) = A'*A\n",
    "\n",
    "println(\"Legends:\")\n",
    "println(\"NM = Newton's method\")\n",
    "println(\"NMPDF1 = Newton's method with non-positive definite Hessian fix, WITH absolute value\")\n",
    "println(\"NMPDF2 = Newton's method with non-positive definite Hessian fix, WITHOUT absolute value\")\n",
    "println(\"BFGS = quasi-Newton method using BFGS approximation of inverse Hessian\")\n",
    "println(\"Correct = the correct outputs a minimizer function should spit out\")\n",
    "println(\"---------------------------------------------------------------------------------------\")\n",
    "@printf(\"%-10s %-40s %20s %20s\\n\", \"Method\", \"Coordinate of optimal point\", \"Value of minimum\", \"# of iterations\")\n",
    "L = minimizenewt(f0,g0,H0,[0;0])\n",
    "@printf(\"%-10s %10f %20f %20f %20i\\n\", \"NM\", L[1], L[2], L[3], L[4])\n",
    "L = minimizenewtnpd(f0,g0,H0,[0;0])\n",
    "@printf(\"%-10s %10f %20f %20f %20i\\n\", \"NMPDF1\", L[1], L[2], L[3], L[4])\n",
    "L = minimizenewtnpd2(f0,g0,H0,[0;0])\n",
    "@printf(\"%-10s %10f %20f %20f %20i\\n\", \"NMPDF2\", L[1], L[2], L[3], L[4])\n",
    "L = minimizeBFGS(f0,g0,eye(length(x0)), [0;0])\n",
    "@printf(\"%-10s %10f %20f %20f %20i\\n\", \"BFGS\", L[1], L[2], L[3], L[4])\n",
    "@printf(\"%-10s %10f %20f %20f %20i\\n\", \"Correct\", 3.0, 1.0, 0.0, 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Nothing to be done\n",
      "INFO: METADATA is out-of-date — you may not have the latest version of Toms566\n",
      "INFO: Use `Pkg.update()` to get the latest versions of your packages\n",
      "WARNING: Base.Uint8 is deprecated, use UInt8 instead.\n",
      "WARNING: Base.Uint8 is deprecated, use UInt8 instead.\n",
      "WARNING: Base.Uint8 is deprecated, use UInt8 instead.\n",
      "WARNING: Base.Uint8 is deprecated, use UInt8 instead.\n",
      "WARNING: Base.Uint8 is deprecated, use UInt8 instead.\n",
      "WARNING: Base.Uint8 is deprecated, use UInt8 instead.\n",
      "INFO: Updating METADATA...\n",
      "INFO: Updating Toms566...\n",
      "INFO: Computing changes...\n",
      "INFO: No packages to install, update or remove\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Toms566\")\n",
    "Pkg.update()\n",
    "using Toms566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legends:\n",
      "NM = Newton's method\n",
      "NMPDF1 = Newton's method with non-positive definite Hessian fix, WITH absolute value\n",
      "NMPDF2 = Newton's method with non-positive definite Hessian fix, WITHOUT absolute value\n",
      "BFGS = quasi-Newton method using BFGS approximation of inverse Hessian\n",
      "---------------------------------------------------------------------------------------\n",
      "                                     # of iterations (-1 = failure)\n",
      "No.  Name                            NM     NMPDF1   NMPDF2   BFGS    \n",
      "  1  Hellical valley                 1      4        10       6       \n",
      "  2  Bigg's EXP6                     -1     -1       -1       15      \n",
      "  3  Gaussian                        1      1        1        2       \n",
      "  4  Powell                          -1     12       3        8       \n",
      "  5  Box 3-dim                       2      3        6        7       \n",
      "  6  Variably dimensioned            6      2        2        1       \n",
      "  7  Watson                          -1     31       -1       4       \n",
      "  8  Penalty I                       4      4        4        2       \n",
      "  9  Penalty II                      -1     4        -1       33      \n",
      " 10  Brown badly scaled              -1     6        6        9       \n",
      " 11  Brown and Denis                 -1     16       47       7       \n",
      " 12  Gulf research and development   -1     21       29       11      \n",
      " 13  Trigonometric                   -1     66       -1       15      \n",
      " 14  Extended rosenbrock             -1     -1       -1       76      \n",
      " 15  Extended Powell singular        -1     -1       -1       7       \n",
      " 16  Beale                           1      4        8        8       \n",
      " 17  Wood                            4      4        4        4       \n",
      " 18  Chebyquad                       -1     -1       -1       51      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "######################################################\n",
    "# Complete test of every functions in Toms566, SLOW! #\n",
    "######################################################\n",
    "\n",
    "println(\"Legends:\")\n",
    "println(\"NM = Newton's method\")\n",
    "println(\"NMPDF1 = Newton's method with non-positive definite Hessian fix, WITH absolute value\")\n",
    "println(\"NMPDF2 = Newton's method with non-positive definite Hessian fix, WITHOUT absolute value\")\n",
    "println(\"BFGS = quasi-Newton method using BFGS approximation of inverse Hessian\")\n",
    "println(\"---------------------------------------------------------------------------------------\")\n",
    "@printf(\"%3s  %-30s  %-30s\", \"\", \"\", \"# of iterations (-1 = failure)\\n\")\n",
    "@printf(\"%3s  %-30s  %-6s %-8s %-8s %-8s\\n\",\n",
    "        \"No.\",\n",
    "        \"Name\",\n",
    "        \"NM\", \n",
    "        \"NMPDF1\",\n",
    "        \"NMPDF2\",\n",
    "        \"BFGS\")\n",
    "for i=1:18\n",
    "    p = Problem(i)\n",
    "    x0 = p.x0       # standard starting point\n",
    "    f = p.obj   # objective value at x\n",
    "    g = p.grd   # gradient at x\n",
    "    H = p.hes   # Hessian at x\n",
    "    \n",
    "    # Keeps track of the number of iterations\n",
    "    iters = [minimizenewt(f,g,H,x0)[end], \n",
    "            minimizenewtnpd(f,g,H,x0)[end],\n",
    "            minimizenewtnpd2(f,g,H,x0)[end],\n",
    "            minimizeBFGS(f,g,eye(length(x0)), x0)[end]]\n",
    "    \n",
    "    # Set the number of iterations to be X if there was an exceeding of max allowed number of iterations\n",
    "    function showFailure(iter)\n",
    "        if iter == DEFAULT_MAX_ITER\n",
    "            return -1\n",
    "        else\n",
    "            return iter\n",
    "        end\n",
    "    end\n",
    "    iters = map(showFailure, iters)\n",
    "\n",
    "    # NM = Newton's method\n",
    "    # NMNPDF = Newton's method with non-positive definite fix\n",
    "    @printf(\"%3i  %-31s %-6i %-8i %-8i %-8i\\n\",\n",
    "            i, \n",
    "            p.name,\n",
    "            iters[1],\n",
    "            iters[2],\n",
    "            iters[3],\n",
    "            iters[4])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0-rc2",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
